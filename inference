import gradio as gr
import torch
from PIL import Image
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from peft import PeftModel

# 1) Load the fine-tuned model and processor
BASE_MODEL = "Salesforce/blip2-opt-2.7b"
PEFT_PATH  = "blip2-lora-opt2.7b-checkpoints/epoch3-val0.8285"
DEVICE     = "mps" if torch.backends.mps.is_available() else "cpu"

processor  = Blip2Processor.from_pretrained(BASE_MODEL, use_fast=True)
base_model = Blip2ForConditionalGeneration.from_pretrained(BASE_MODEL)
model      = PeftModel.from_pretrained(base_model, PEFT_PATH)
model.to(DEVICE)
model.eval()

# 2) Inference function
def generate_report(image: Image.Image) -> str:
    if image.mode != "RGB":
        image = image.convert("RGB")
    inputs = processor(images=image, return_tensors="pt").to(DEVICE)
    generated = model.generate(
        **inputs,
        max_new_tokens=256,
        num_beams=5,
        no_repeat_ngram_size=3,
        repetition_penalty=2.0,
        length_penalty=0.7,
        early_stopping=True,
        eos_token_id=processor.tokenizer.eos_token_id,
        pad_token_id=processor.tokenizer.pad_token_id
    )
    caption = processor.batch_decode(generated, skip_special_tokens=True)[0]
    return caption

# 3) Gradio app
iface = gr.Interface(
    fn=generate_report,
    inputs=gr.Image(type="pil", label="Upload X-ray Image"),
    outputs=gr.Textbox(label="Generated Report"),
    title="Radiology Report Generator",
    description="Upload a chest X-ray image (PNG, JPG, etc.) to generate a radiology report."
)

if __name__ == "__main__":
    iface.launch()
